{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoFeatureExtractor, SwinModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in directory: 128361\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "image_dir = 'images/cellphone'\n",
    "\n",
    "# 파일 목록 확인\n",
    "try:\n",
    "    files = os.listdir(image_dir)\n",
    "    print(f\"Number of files in directory: {len(files)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kms10\\AppData\\Local\\anaconda3\\envs\\py3_12\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Swin Transformer setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\").to(device)\n",
    "model.eval()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Precision (FP16) 설정\n",
    "scaler = torch.amp.GradScaler(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=extractor.image_mean, std=extractor.image_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터셋 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_files = [os.path.join(image_dir, file_name) for file_name in os.listdir(image_dir) if file_name.endswith(\".jpg\") and '_' in file_name]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = transform(image)\n",
    "        file_name = os.path.basename(image_path)\n",
    "\n",
    "        try:\n",
    "            post_id = int(file_name.split('_')[0])  # post_id 추출\n",
    "        except ValueError:\n",
    "            print(f\"Invalid file name format: {file_name}\")\n",
    "            post_id = -1  # 잘못된 파일 이름의 경우 예외 처리\n",
    "\n",
    "        return post_id, image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 설정 (멀티프로세싱 적용)\n",
    "batch_size = 32  # 배치 크기 설정\n",
    "dataset = ImageDataset(image_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image: images/cellphone\\10000_1.jpg\n",
      "Loaded image: images/cellphone\\10000_2.jpg\n",
      "Loaded image: images/cellphone\\10000_3.jpg\n",
      "Loaded image: images/cellphone\\10001_1.jpg\n",
      "Loaded image: images/cellphone\\10001_2.jpg\n"
     ]
    }
   ],
   "source": [
    "for image_file in dataset.image_files[:5]:  # 첫 5개 이미지 확인\n",
    "    try:\n",
    "        image = Image.open(image_file).convert(\"RGB\")\n",
    "        print(f\"Loaded image: {image_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4012/4012 [1:27:27<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference, mixed precision 및 DataLoader를 사용한 임베딩 추출 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 중간 저장 파일 경로\n",
    "output_file = 'swin_image_embeddings_partial.csv'\n",
    "\n",
    "# 중간에 저장된 결과가 있는지 확인하고 이어서 작업\n",
    "if os.path.exists(output_file):\n",
    "    df = pd.read_csv(output_file)\n",
    "    processed_post_ids = df['post_id'].tolist()\n",
    "else:\n",
    "    processed_post_ids = []\n",
    "\n",
    "# 임베딩 저장을 위한 데이터 구조\n",
    "image_data = {}\n",
    "\n",
    "# 배치 단위로 이미지 처리\n",
    "for batch in tqdm(dataloader):\n",
    "    post_ids, image_tensors = batch\n",
    "    image_tensors = image_tensors.to(device)\n",
    "\n",
    "    # 이미 처리된 post_id는 건너뛰기\n",
    "    post_ids = [post_id for post_id in post_ids if post_id not in processed_post_ids]\n",
    "\n",
    "    if not post_ids:\n",
    "        continue  # 모든 post_id가 이미 처리된 경우 건너뛰기\n",
    "\n",
    "    # FP16 mixed precision inference\n",
    "    with torch.amp.autocast(\"cuda\"):  # FP16 적용\n",
    "        with torch.no_grad():\n",
    "            outputs = model(pixel_values=image_tensors)\n",
    "\n",
    "    # 임베딩 추출\n",
    "    batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    # 각 이미지에 대해 post_id에 따라 임베딩 저장 및 바로 CSV에 기록\n",
    "    with open(output_file, mode='a') as f:\n",
    "        for idx, post_id in enumerate(post_ids):\n",
    "            if post_id != -1:  # 잘못된 파일이 아닌 경우에만 처리\n",
    "                post_id = int(post_id.item())\n",
    "                embedding = batch_embeddings[idx]\n",
    "                embedding_str = ','.join(map(str, embedding.tolist()))  # 임베딩을 문자열로 변환\n",
    "                f.write(f\"{post_id},{embedding_str}\\n\")\n",
    "\n",
    "    # GPU 메모리 해제\n",
    "    torch.cuda.empty_cache()  # 각 배치 처리 후에 메모리 해제\n",
    "\n",
    "print(\"Batch inference, mixed precision 및 DataLoader를 사용한 임베딩 추출 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
